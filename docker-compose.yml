version: "3.8"

# ==============================================================================
# ANCHORS
# ==============================================================================

x-logging: &default-logging
  driver: "json-file"
  options:
    max-size: "500k"
    max-file: "20"

x-entrypoint-kibana: &default-entrypoint-kibana
  entrypoint: >
    /bin/sh -c "
      set -e
        /usr/local/bin/wait && /usr/local/bin/kibana-docker
      /bin/bash || exit 0
    "

x-entrypoint-kafka: &default-entrypoint-kafka
  entrypoint: >
    /bin/sh -c "
      set -e
        /usr/local/bin/wait && /etc/confluent/docker/run
      /bin/bash || exit 0
    "

x-entrypoint-kafka-connect-ui: &default-entrypoint-kafka-connect-ui
  entrypoint: >
    /bin/sh -c "
      set -e
        /usr/local/bin/wait && /run.sh
      /bin/bash || exit 0
    "

x-volumes: &default-volumes
  volumes:
    - ./scripts/wait:/usr/local/bin/wait

x-volumes-kafka: &default-volumes-kafka
  volumes:
    - ./scripts/wait:/usr/local/bin/wait
    - ./logs/zk-single-kafka-single/kafka/data:/var/lib/kafka/data

# ==============================================================================
# SERVICES
# ==============================================================================

services:

# ==============================================================================
# ELASTICSEARCH + KIBANA
# ==============================================================================

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.2.0
    container_name: elasticsearch
    environment:
      - node.name=elasticsearch
      - discovery.seed_hosts=elasticsearch01
      - cluster.initial_master_nodes=elasticsearch,elasticsearch01
      - cluster.name=docker-cluster
      - bootstrap.memory_lock=true
      - 'ES_JAVA_OPTS=-Xms2048m -Xmx2048m'
    ports:
      - target: 9200
        published: 9200
        protocol: tcp
        mode: host
    healthcheck:
      test: ["CMD-SHELL", "curl --silent --fail localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 30s
      retries: 10
    ulimits:
      memlock:
        soft: -1
        hard: -1
    privileged: true
    restart: on-failure
    logging: *default-logging
    volumes: [ "elasticsearch_1:/usr/share/elasticsearch/data" ]

  elasticsearch01:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.2.0
    container_name: elasticsearch01
    environment:
      - node.name=elasticsearch01
      - discovery.seed_hosts=elasticsearch
      - cluster.initial_master_nodes=elasticsearch,elasticsearch01
      - cluster.name=docker-cluster
      - bootstrap.memory_lock=true
      - 'ES_JAVA_OPTS=-Xms512m -Xmx512m'
    ulimits:
      memlock:
        soft: -1
        hard: -1
    privileged: true
    restart: on-failure
    logging: *default-logging
    volumes: [ "elasticsearch_2:/usr/share/elasticsearch/data" ]

  kibana:
    image: docker.elastic.co/kibana/kibana:7.2.0
    container_name: kibana
    env_file: [ "./.env", "./code/environments/kibana.env" ]
    <<: *default-entrypoint-kibana
    ports:
      - target: 5601
        published: 5601
        protocol: tcp
        mode: host
    healthcheck:
      test: ["CMD-SHELL", "curl --silent --fail http://localhost:5601/ || exit 1"]
      interval: 30s
      timeout: 30s
      retries: 10
    restart: on-failure
    logging: *default-logging
    depends_on: [ "elasticsearch" ]
    <<: *default-volumes

# ==============================================================================
# KAFKA
# ==============================================================================

  zookeeper:
    image: zookeeper:3.4.9
    container_name: zookeeper
    env_file: [ "./.env", "./code/environments/zookeeper.env" ]
    ports:
      - target: 2181
        published: 2181
        protocol: tcp
        mode: host
    restart: on-failure
    logging: *default-logging
    volumes: [ "./logs/zk-single-kafka-single/zookeeper/data:/data", "./logs/zk-single-kafka-single/zookeeper/datalog:/datalog" ]

  kafka:
    image: confluentinc/cp-kafka:5.3.0
    container_name: kafka
    env_file: [ "./.env", "./code/environments/kafka.env" ]
    <<: *default-entrypoint-kafka
    ports:
      - target: 9092
        published: 9092
        protocol: tcp
        mode: host
    restart: on-failure
    logging: *default-logging
    depends_on: [ "zookeeper" ]
    <<: *default-volumes-kafka

  kafka-connect:
    image: confluentinc/cp-kafka-connect:5.3.0
    container_name: kafka-connect
    env_file: [ "./.env", "./code/environments/kafka-connect.env" ]
    networks:
      default:
        aliases:
          - default
      realtime-processing:
        aliases:
          - realtime-processing
    ports:
      - target: 8083
        published: 8083
        protocol: tcp
        mode: host
    restart: on-failure
    logging: *default-logging
    depends_on: [ "zookeeper", "kafka" ]
    volumes: [ "./logs/connectors:/etc/kafka-connect/jars/" ]

  kafka-connect-ui:
    image: landoop/kafka-connect-ui:0.9.7
    container_name: kafka-connect-ui
    env_file: [ "./.env", "./code/environments/kafka-connect-ui.env" ]
    <<: *default-entrypoint-kafka-connect-ui
    ports:
      - target: 8000
        published: 8003
        protocol: tcp
        mode: host
    restart: on-failure
    logging: *default-logging
    depends_on: [ "kafka-connect" ]
    <<: *default-volumes

  kafka-manager:
    image: sheepkiller/kafka-manager:latest
    container_name: kafka-manager
    env_file: [ "./.env", "./code/environments/kafka-manager.env" ]
    ports:
      - target: 9000
        published: 9000
        protocol: tcp
        mode: host
    depends_on: [ "zookeeper", "kafka" ]
    links: [ "zookeeper", "kafka" ]

# ==============================================================================
# NETWORKS
# ==============================================================================

networks:
  realtime-processing:
    driver: bridge

# ==============================================================================
# VOLUMES
# ==============================================================================

volumes:
  elasticsearch_1:
    driver: local
  elasticsearch_2:
    driver: local
